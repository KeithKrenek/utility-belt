{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf299e7e",
   "metadata": {},
   "source": [
    "# Merge Files to Plain Text\n",
    "\n",
    "A reusable, documented notebook for consolidating files from a folder into a single `.txt` file for downstream tasks (search, LLM context building, archiving, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953754d5",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook recursively scans a folder, filters by allowed file extensions, and merges file contents into a single plain-text output.\n",
    "It is designed to be **copy/paste friendly** for open-source use and reproducible across environments.\n",
    "\n",
    "### Features\n",
    "- Simple, configurable **parameters** section (no code changes needed).\n",
    "- Robust file handling with sensible defaults (UTF-8 with graceful fallbacks).\n",
    "- Skips binary or oversized files (configurable), with a per-file header to retain provenance.\n",
    "- Optional exclusion patterns (e.g., `node_modules`, `.git`, build artifacts).\n",
    "- Deterministic output ordering for reproducibility.\n",
    "\n",
    "### What it does *not* do (by default)\n",
    "- Parse proprietary binary formats (e.g., `.docx`, `.pdf`). You can add readers in the `READERS` map if desired.\n",
    "- Preserve exact original encodingsâ€”content is normalized to UTF-8 in the merged file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48afd0e",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "- Python 3.8+\n",
    "- Standard library only (no external dependencies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e09f8",
   "metadata": {},
   "source": [
    "## Quick Start\n",
    "\n",
    "1. Set the parameters in the **Configuration** cell below (at minimum `INPUT_DIR` and `OUTPUT_TXT`).  \n",
    "2. Run the notebook cells from top to bottom.  \n",
    "3. Find the merged text at the path you configured in `OUTPUT_TXT`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d6b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration ===\n",
    "from pathlib import Path\n",
    "\n",
    "# Folder to scan (recursive). Use an absolute or relative path.\n",
    "INPUT_DIR = Path(r\"C:\\Users\\keith\\Downloads\\resume-pdf-layouter\")  # e.g., Path(\"/path/to/project\")\n",
    "\n",
    "# Where to write the merged text file.\n",
    "OUTPUT_TXT = Path(r\"C:\\Users\\keith\\Downloads\\resume-pdf-layouter-altogether.txt\")\n",
    "\n",
    "# Include files with these extensions (lowercase, include the dot).\n",
    "INCLUDE_EXTS = {\n",
    "    \".txt\", \".md\", \".py\", \".json\", \".yaml\", \".yml\", \".toml\", \".tsx\", \".mjs\",\n",
    "    \".csv\", \".tsv\", \".xml\", \".ini\", \".cfg\", \".html\", \".css\", \".js\", \".ts\"\n",
    "}\n",
    "\n",
    "# Exclude paths that **contain** any of these substrings (case-insensitive).\n",
    "EXCLUDE_SUBSTRINGS = {\"node_modules\", \".git\", \"__pycache__\", \"build\", \"dist\", \".venv\", \".mypy_cache\", \n",
    "                      \"resume_pdf_layouter_mvp_full_repo\", \"resume-pdf-layouter-altogether.txt\", \"package-lock\",\n",
    "                      \".next\", \"sample-resume.md\"}\n",
    "\n",
    "# Max size per file in bytes (skip if larger). Set to None to disable.\n",
    "MAX_FILE_BYTES = None # 2 * 1024 * 1024  # 2 MB\n",
    "\n",
    "# Whether to include a header with file path and size before each file's content.\n",
    "INCLUDE_FILE_HEADERS = True\n",
    "\n",
    "# Whether to include an end-of-file marker after each file.\n",
    "INCLUDE_EOF_MARKERS = True\n",
    "\n",
    "# If True, use relative paths to INPUT_DIR in headers; otherwise use absolute paths.\n",
    "USE_RELATIVE_PATHS = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6735b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helpers ===\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def is_excluded(path: Path, exclude_substrings):\n",
    "    p = str(path).lower()\n",
    "    return any(substr.lower() in p for substr in exclude_substrings)\n",
    "\n",
    "def safe_read_text(path: Path, max_bytes=None) -> str:\n",
    "    \"\"\"\n",
    "    Read a file as text using UTF-8 with fallbacks. Truncates if max_bytes is specified.\n",
    "    Returns the (possibly truncated) text content.\n",
    "    \"\"\"\n",
    "    if max_bytes is not None and path.stat().st_size > max_bytes:\n",
    "        raise ValueError(f\"File too large ({path.stat().st_size} bytes)\")\n",
    "\n",
    "    # Basic binary sniff: read a small chunk to detect null bytes\n",
    "    try:\n",
    "        with open(path, \"rb\") as rb:\n",
    "            head = rb.read(2048)\n",
    "            if b\"\\x00\" in head:\n",
    "                raise UnicodeDecodeError(\"utf-8\", head, 0, 1, \"binary data detected\")\n",
    "    except Exception as e:\n",
    "        # If we fail to open in binary for sniffing, we'll try text anyway\n",
    "        pass\n",
    "\n",
    "    # Try utf-8 first, then latin-1 as a last resort to avoid crashing\n",
    "    try:\n",
    "        return path.read_text(encoding=\"utf-8\", errors=\"strict\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            return path.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "        except Exception:\n",
    "            return path.read_text(encoding=\"latin-1\", errors=\"replace\")\n",
    "\n",
    "def discover_files(root: Path, include_exts, exclude_substrings):\n",
    "    files = []\n",
    "    for p in sorted(root.rglob(\"*\")):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        if include_exts and p.suffix.lower() not in include_exts:\n",
    "            continue\n",
    "        if is_excluded(p, exclude_substrings):\n",
    "            continue\n",
    "        files.append(p)\n",
    "    return files\n",
    "\n",
    "def format_header(path: Path, root: Path, size: int) -> str:\n",
    "    shown = path.relative_to(root) if USE_RELATIVE_PATHS else path.resolve()\n",
    "    return f\"\"\"\n",
    "===== FILE: {shown} | SIZE: {size} bytes =====\n",
    "\"\"\"\n",
    "\n",
    "def format_footer() -> str:\n",
    "    return \"\\n===== END FILE =====\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dc351a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered 23 files. Merging...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keith\\AppData\\Local\\Temp\\ipykernel_10052\\1901250185.py:19: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  out.write(f\"# Timestamp: {datetime.utcnow().isoformat()}Z\\n\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote 23 files into: C:\\Users\\keith\\Downloads\\resume-pdf-layouter-altogether.txt\n"
     ]
    }
   ],
   "source": [
    "# === Merge Execution ===\n",
    "from datetime import datetime\n",
    "\n",
    "root = INPUT_DIR.resolve()\n",
    "files = discover_files(root, INCLUDE_EXTS, EXCLUDE_SUBSTRINGS)\n",
    "\n",
    "if not files:\n",
    "    print(\"No files found with current filters.\")\n",
    "else:\n",
    "    print(f\"Discovered {len(files)} files. Merging...\")\n",
    "\n",
    "written = 0\n",
    "skipped = 0\n",
    "err_files = []\n",
    "with open(OUTPUT_TXT, \"w\", encoding=\"utf-8\") as out:\n",
    "    # Provenance header\n",
    "    out.write(\"# Merged Text Export\\n\")\n",
    "    out.write(f\"# Source root: {root}\\n\")\n",
    "    out.write(f\"# Timestamp: {datetime.utcnow().isoformat()}Z\\n\")\n",
    "    out.write(f\"# Files included: {len(files)}\\n\\n\")\n",
    "\n",
    "    for f in files:\n",
    "        try:\n",
    "            content = safe_read_text(f, max_bytes=MAX_FILE_BYTES)\n",
    "            if INCLUDE_FILE_HEADERS:\n",
    "                out.write(format_header(f, root, f.stat().st_size))\n",
    "            out.write(content)\n",
    "            if INCLUDE_EOF_MARKERS:\n",
    "                out.write(format_footer())\n",
    "            written += 1\n",
    "        except Exception as e:\n",
    "            skipped += 1\n",
    "            err_files.append((str(f), str(e)))\n",
    "\n",
    "print(f\"Done. Wrote {written} files into: {OUTPUT_TXT}\")\n",
    "if skipped:\n",
    "    print(f\"Skipped {skipped} files due to errors or filters.\")\n",
    "if err_files:\n",
    "    print(\"First few errors:\")\n",
    "    for item in err_files[:5]:\n",
    "        print(\" -\", item[0], \"->\", item[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e21c3da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size: 47556 bytes\n",
      "# Merged Text Export\n",
      "# Source root: C:\\Users\\keith\\Downloads\\resume-pdf-layouter\n",
      "# Timestamp: 2025-09-11T02:33:53.007676Z\n",
      "# Files included: 23\n",
      "\n",
      "\n",
      "===== FILE: app\\api\\render\\route.ts | SIZE: 1190 bytes =====\n",
      "// app/api/render/route.ts\n",
      "// File: app/api/render/route.ts\n",
      "import { NextRequest } from \"next/server\";\n",
      "import { z } from \"zod\";\n",
      "import { mdToHtml } from \"@/lib/markdown\";\n",
      "import { renderBestPdf, renderSinglePdf } from \"@/lib/optimizer\";\n",
      "import { Layout, PageSize } from \"@/lib/types\";\n",
      "\n",
      "const Body = z.object({\n",
      "  markdown: z.string(),\n",
      "  layout: z.enum([\"one\", \"two-eq\", \"two-4060\"]).default(\"one\"),\n",
      "  pageSize: z.enum([\"letter\", \"a4\"]).default(\"letter\"),\n",
      "  optimize: z.boolean().default(true),\n",
      "  maxPages: z.number().int().min(1).max(10).optional().nullable(), // NEW\n",
      "});\n",
      "\n",
      "export async function POST(req: NextRequest) {\n",
      "  const json = await req.json();\n",
      "  const body = Body.parse(json);\n",
      "  const rendered = mdToHtml(body.markdown);\n",
      "\n",
      "  const pdf = body.optimize\n",
      "    ? await renderBestPdf(rendered, \n"
     ]
    }
   ],
   "source": [
    "# === Validate Output & Preview ===\n",
    "from pathlib import Path\n",
    "\n",
    "if Path(OUTPUT_TXT).exists():\n",
    "    print(\"Output size:\", Path(OUTPUT_TXT).stat().st_size, \"bytes\")\n",
    "    # Show the first ~1000 chars for a quick check (non-destructive)\n",
    "    preview = Path(OUTPUT_TXT).read_text(encoding=\"utf-8\", errors=\"replace\")[:1000]\n",
    "    print(preview)\n",
    "else:\n",
    "    print(\"No output found. Did the merge run successfully?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200f52c9",
   "metadata": {},
   "source": [
    "## Extending This Notebook\n",
    "\n",
    "- To support other file types (e.g., `.pdf`, `.docx`), add specialized readers in a `READERS` map and update `discover_files` to include those extensions.  \n",
    "- To add a CLI, convert the logic into a standalone script and parse args with `argparse`.  \n",
    "- For large repositories, consider stream processing or chunking the output by directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f7f90e",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "This notebook is provided under the MIT License. See `LICENSE` in your repository for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6206438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.2 (tags/v3.13.2:4f8bb39, Feb  4 2025, 15:23:48) [MSC v.1942 64 bit (AMD64)]\n",
      "Platform: Windows-11-10.0.26100-SP0\n"
     ]
    }
   ],
   "source": [
    "# === Environment Info (Optional) ===\n",
    "import sys, platform\n",
    "print(\"Python:\", sys.version.replace(\"\\n\",\" \"))\n",
    "print(\"Platform:\", platform.platform())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
